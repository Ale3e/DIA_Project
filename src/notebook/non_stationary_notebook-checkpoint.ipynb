{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from algorithms.ThompsonSampling.Non_Stationary_Environment import *\n",
    "from algorithms.ThompsonSampling.TS_Learner import *\n",
    "from algorithms.ThompsonSampling.SWTS_Learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_arms = 3\n",
    "#prices = np.array([300, 325, 350, 375, 400, 425, 450, 475])\n",
    "#p1 = [[0.045, 0.04, 0.0325, 0.0275, 0.0250, 0.02, 0.0175, 0.0125],\n",
    " #             [0.045, 0.04, 0.0325, 0.0275, 0.0250, 0.02, 0.0175, 0.0125],\n",
    "  #            [0.035, 0.03, 0.0225, 0.0175, 0.015, 0.01, 0.0075, 0.0025],\n",
    "   #           [0.037, 0.032, 0.0245, 0.0195, 0.0170, 0.0120, 0.0095, 0.0045]]\n",
    "\n",
    "prices = np.array(list(range(300,500,40)))\n",
    "n_arms = np.size(prices)\n",
    "\n",
    "p = []\n",
    "for i in range(0,4):\n",
    "    if(i == 0):\n",
    "        a = np.random.uniform(0.5,0,size=n_arms)\n",
    "        a = np.sort(a)\n",
    "        p.append(a[::-1]) \n",
    "    if(i == 1):\n",
    "        p.append(p[0])\n",
    "    if(i == 2):\n",
    "        a = np.random.uniform(0.4,0,size=n_arms)\n",
    "        a = np.sort(a)\n",
    "        p.append(a[::-1]) \n",
    "    if(i == 3):\n",
    "        a = np.random.uniform(0.45,0,size=n_arms)\n",
    "        a = np.sort(a)\n",
    "        p.append(a[::-1]) \n",
    "\n",
    "\n",
    "p = np.array(p)  \n",
    "print(p)\n",
    "    \n",
    "    \n",
    "\n",
    "T = 365\n",
    "\n",
    "n_experiments = 100\n",
    "ts_rewards_per_experiment = []\n",
    "swts_rewards_per_experiment = []\n",
    "window_size = int(np.sqrt(T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0, n_experiments):\n",
    "    ts_env = Non_Stationary_Environment(n_arms=n_arms, probabilities=p, horizon=T, price=prices)\n",
    "    ts_learner = TS_Learner(n_arms=n_arms)\n",
    "\n",
    "    swts_env = Non_Stationary_Environment(n_arms=n_arms, probabilities=p, horizon=T, price=prices)\n",
    "    swts_learner = SWTS_Learner(n_arms=n_arms, window_size=window_size)\n",
    "\n",
    "    for t in range(0, T):\n",
    "        pulled_arm = ts_learner.pull_arm()\n",
    "        reward = ts_env.round(pulled_arm)\n",
    "        reward_price = ts_env.round_price(pulled_arm)\n",
    "        ts_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = swts_learner.pull_arm()\n",
    "        reward = swts_env.round(pulled_arm)\n",
    "        swts_learner.update(pulled_arm, reward)\n",
    "\n",
    "    ts_rewards_per_experiment.append(ts_learner.collected_rewards)\n",
    "    swts_rewards_per_experiment.append(swts_learner.collected_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_instantaneous_regret = np.zeros(T)\n",
    "swts_instantaneous_regret = np.zeros(T)\n",
    "n_phases = len(p)\n",
    "phases_len = T/n_phases\n",
    "opt_per_phases = p.max(axis=1)\n",
    "optimum_per_round = np.zeros(T)\n",
    "\n",
    "for i in range(0, n_phases):\n",
    "    optimum_per_round[int(i*phases_len) : int((i+1)*phases_len)] = opt_per_phases[i]\n",
    "    ts_instantaneous_regret[int(i*phases_len) : int((i+1)*phases_len)] = opt_per_phases[i] - np.mean(ts_rewards_per_experiment, axis=0)[int(i*phases_len)]\n",
    "    swts_instantaneous_regret[int(i*phases_len) : int((i+1)*phases_len)] = opt_per_phases[i] - np.mean(swts_rewards_per_experiment, axis=0)[int(i*phases_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.plot(np.mean(ts_rewards_per_experiment, axis=0), 'r')\n",
    "plt.plot(np.mean(swts_rewards_per_experiment, axis=0), 'b')\n",
    "plt.plot(optimum_per_round, '--k')\n",
    "plt.legend([\"TS\", \"SW-TS\", \"Optimum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.plot(np.cumsum(ts_instantaneous_regret), 'r')\n",
    "plt.plot(np.cumsum(swts_instantaneous_regret), 'b')\n",
    "plt.legend([\"TS\", \"SW-TS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
